# Khadijetou_Nourdine_C17879_2026_Machine_learning
# üìë Rapport de Mini-Projet : Apprentissage Supervis√© Lin√©aire

**√âtudiante :** Khadijetou Nourdine Sow (C17879)  
**Niveau :** Master IA  
**Ann√©e :** 2026

---

##  Introduction
L‚Äôid√©e du projet est de comprendre comment pr√©dire une valeur num√©rique continue comme un prix ou un cout √† partir de donn√©es historiques pour nous permettre d‚Äôapprendre √† :
* **Pr√©parer** les donn√©es.
* **Cr√©er** un mod√®le math√©matique.
* **Mesurer** si le mod√®le choisi est efficace ou pas.

---

## Partie 1 : R√©gression Lin√©aire
J‚Äôai choisi d'utiliser **Medical Insurance Cost** sur Kaggle comme jeu de donn√©es de r√©gression. Une fois le mod√®le trouv√©, j‚Äôai t√©l√©charg√© le fichier `.csv` et l‚Äôai import√© dans le notebook avec la biblioth√®que **Pandas**.

### 1. Analyser les corr√©lations via une matrice de chaleur (Heatmap)
J‚Äôai utilis√© les biblioth√®ques `seaborn` et `matplotlib` pour g√©n√©rer une matrice de chaleur (Heatmap) pour pouvoir graphiquement voir si l‚Äôune des variables comme l'√¢ge avait une forte influence sur le co√ªt de l‚Äôassurance.

**Observations :**
* Avec l'√¢ge, les frais m√©dicaux ont tendance √† augmenter (**0,299**).
* L‚ÄôIMC (**0,198**) m√®ne parfois √† des frais m√©dicaux plus √©lev√©s.
* Le nombre d'enfants (**0,068**) n‚Äôa pas une grande influence sur les frais m√©dicaux.



### 2. Formaliser le mod√®le (Algorithme ML)
Le but est de pr√©dire $y$ qui repr√©sente les frais m√©dicaux (charges) en fonction de $x$ (l'√¢ge, bmi, children). La r√©gression lin√©aire mod√©lise la relation entre $y$ et $X$ comme une combinaison lin√©aire selon l'algorithme :
$$ y = Œ≤0 + PŒ≤ixi + œµ$$

### 3. √âvaluer la performance (R2 et MSE)
On a fait l'entra√Ænement du mod√®le avec **scikit-learn** en s√©parant nos donn√©es en 2 parties : 
* **Train set :** pour que le mod√®le apprenne les relations.
* **Test set :** pour v√©rifier si le mod√®le peut pr√©dire sur des donn√©es jamais vues.

**R√©sultats obtenus :**
* **R¬≤ de 0.78** : indique que 78% de la variabilit√© des frais est expliqu√©e par le mod√®le.
* **RMSE de 5796.28 ‚Ç¨** : repr√©sente l'erreur moyenne de pr√©diction du mod√®le en euros.

### 4. Interpr√©tation des coefficients $\beta_i$
Chaque coefficient correspond au "poids" d'une variable. On voit que le facteur le plus d√©terminant pour les frais m√©dicaux est **d'√™tre fumeur**, suivi par l'IMC, le nombre d'enfants et l'√¢ge. Le sexe a un impact minimal et la r√©gion a une influence mod√©r√©e.

---

## üß™ Partie 2 : R√©gression Logistique
Le but est de chercher √† classer les fleurs et √† transformer ces classes en binaires.

### 1. Pr√©parer les donn√©es et normaliser les variables d‚Äôentr√©e
On a charg√© le dataset et transform√© le probl√®me de 3 classes en un probl√®me binaire (oui/non). On a utilis√© le **StandardScaler** car la r√©gression logistique utilise la fonction sigmo√Øde et des calculs de distance.

### 2. Mod√©liser la probabilit√© via la fonction sigmo√Øde (Algorithme ML)
Afin de transformer un score lin√©aire en une probabilit√© entre 0 et 1, on utilise **LogisticRegression** qui g√®re automatiquement la fonction :
$$P(y = 1|x) = \frac{1}{1+e^{-z}}$$
* Si $P > 0.5$, l'IA pr√©dit la classe 1.
* Si $P < 0.5$, l'IA pr√©dit la classe 0.

### 3. √âvaluer le mod√®le via une Matrice de Confusion
Pour √©valuer si mon mod√®le s‚Äôest tromp√© de fleurs, j‚Äôai g√©n√©r√© une matrice de confusion. J‚Äôai obtenu **1.00** partout, ce qui signifie que le mod√®le ne s‚Äôest pas tromp√© sur le dataset. Cette performance parfaite (Accuracy de 100%) d√©montre que les classes sont lin√©airement s√©parables dans l'espace des caract√©ristiques apr√®s normalisation.

### 4. Calculer l‚ÄôAccuracy, la Pr√©cision et le Rappel (Recall)
L'obtention de scores parfaits (**1.00**) s'explique par la nature du dataset **Iris**. Dans le cadre de cette classification binaire (Classe 0 vs Autres), les caract√©ristiques physiques de l'esp√®ce Setosa sont radicalement diff√©rentes des autres esp√®ces. G√©om√©triquement, il existe une fronti√®re nette que la r√©gression logistique peut tracer sans aucune erreur de classement.

---

## ‚úÖ Conclusion
La r√©gression lin√©aire est id√©ale pour pr√©dire une valeur exacte, tandis que la r√©gression logistique excelle pour la classification. La qualit√© des r√©sultats d√©pend avant tout de la pr√©paration des donn√©es (encodage et normalisation).

